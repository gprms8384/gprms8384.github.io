---

title : "CNN(Convolution Neural Network) 합성곱 신경망"
excerpt : "특성 맵과 패딩, 그리고 풀링"

categories:
    - KDL
tages:
    - KDL

toc : true
toc_sticky: true

date: 2022-02-23
#last_modified_at: 2021-09-11

---
# 1. 합성곱 신경망(CNN)

## 1. 합성곱 연산

    -  Dense 층은 입력 특성 공간에 있는 전역패턴을 학습하지만 합성곱 층은 지역 패턴을 학습힌다.

    - **합성곱 신경망의 지역패턴 학습(아래)**

 ![image](https://user-images.githubusercontent.com/37393115/155303570-ca5963e7-6ec6-4ed3-83ec-45867f4c6348.gif)

- 위의 특징은 두 가지 흥미로운 성질을 제공한다.
  
  - 학습된 패턴은 평행 이동 불변성을 가진다.(우리가 보는 세상은 평행 이동으로 인해 다르게 인식되지 않는다.)
  
  - 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있다. 이는 예를 들어 첫 번쨰 합성곱 층이 작은 지역의 패턴을 학습하면 다음 층은 첫 번째 층의 특성으로 구성된 더 큰 패턴을 학습하는 형식이라고 볼 수 있다.

- 합성곱 연상은 특성 맵이라고 부르는 3D텐서에 적용된다. (2개의 공간축과 1개의 깊이축으로 구성됨)

- 이런 특성 맵에서 작은 패치(patch)들을 추출하고, 모든 패치에 같은 변환을 적용하여 출력 특성 맵을 만든다.

- 출력 텐서에서의 깊이는 층의 매개변수로 결정되기 때문에 상황에 따라 다르게 된다. 

### - 합성곱의 핵심 파라미터

    - 입력으로 뽑아낼 패치의 크기

    - 특성 맵의 출력 깊이

- 케라스의 Conv2D 층에서의 위의 파라미터는 Conv2D(output_depth, (window_height, window_width))처럼 나타난다.

![image](https://user-images.githubusercontent.com/37393115/155305310-a868f5e8-6c2f-403d-a43c-a49652ef6d06.jpeg)

### - 경계 문제와 패딩 이해하기

    - 출력 높이와 너비는 입력의 높이 너비와 다를 수 있다. 이를 해결하는데 **패딩**을 사용한다.

    - 패딩 : 입력과 동일한 너비를 가지기 위해 입력 특성 맵의 가장자리에 적절한 개수의 행과 열을 추가한다. 

### - 합성곱 스트라이드

    - 필터를 적용하는 위치의 간격을 말한다.

    - 스트라이드를 키우면 출력 크기는 작아 진다.

    - 하지만 실전에서는 스트라이드 합성곱은 드물게 사용된다. 오히려 특성 맵을 다운샘플링을 하기 위해서는 최대 풀링연산을 사용하는 경우가 많다.

![image](https://user-images.githubusercontent.com/37393115/155310069-fbf1c28c-65c8-44e3-9d51-0018a0ca6ea4.png)

### - 최대 풀링 연산

    - 스트라이드 합성곱과 비슷하게 강제적으로 특성 맵을 다운샘플링 하는 것을 말한다.

    - 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별로 최댓값을 출력한다.

    - 합성곱과 개념적으로 비슷하지만 추출한 패치에 학습된 선형 변환을 적용하는 대신 하드코딩된 최댓값 추출 연산을 사용합니다.

    - 최대 풀링 연산 이외에도 **평균 풀링**을 사용할 수도 있다.  가장 좋은 방법은 스트라이드가 없는 합성곱으로 조밀한 특성 맵을 만들고 작은 패치에 대해 최대로 활성화된 특성을 고르는 것이다.
