---
title : "머신러닝의 분류와 평가 처리과정"
excerpt : "머신러닝의 분류와 전반적인 과정과 평과에 관하여"

categories:
    - KDL
tages:
    - KDL

toc : true
toc_sticky: true

date: 2022-02-16
#last_modified_at: 2021-09-11
---
# 1. 머신러닝의 네 가지 분류

## 1. 지도 학습
- 가장 흔한 경우, 샘플데이터와 타깃을 이용해 입력 데이터를 맵핑하는 방법을 학습한다.
- 광학 문자판독, 음성인식, 이미지 분류, 언어번역과 같은 딥러닝의 거의 모든 애플리케이션이 속함
- 지도학습은 대부분 분류와 회귀로 이루어짐
- 예외 
    - 시퀀스 생성 : 사진이 주어지면 이를 설명하는 캡션을 생성
    - 구문 트리예측 : 문자잉 주어지면 분해된 구문 트리를 예측한다.
    - 물체 감지 : 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자를 그리는 것
    - 이미지 분할 : 사진이 주어졌을 때 픽셀 단위로 특정 물체에 마스킹을 한다.

## 2. 비지도 학습
- 타깃을 사용하지 않고 입력 데이터에 대한 변환을 찾는 방법
- 지도 학습 문제를 풀기 전 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계
- **차원축소**와 **군집** 등이 있음

## 3. 자기 지도 학습
- 지도 학습의 특별한 경우, 지도 학습이지만 사람이 개입하지 않는다. 경험적인 알고리즘을 사용해서 입력 데이터로부터 생성한다.

## 4. 강화 학습
- 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다.
- 강화 학습에서 **에이전트**는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습된다.
- 현재도 연구가 활발히 진행 중

# 2. 머신 러닝 모델 평가
- 머신 러닝의 목표는 **“처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는 것”** 이다. 
- 이를 위해서는 모델의 일반화 성능에 대한 신뢰할 수 있는 측정방법이 필요하다.

## 1. 훈련, 검증, 테스트 세트
- 모델 평가의 핵심은 가용한 데이터를 훈련, 검증, 테스트 세트로 나누는 것이다.
- 훈련세트로 모델을 훈련하고 검증세트를 이용해 모델의 성능을 평가한 뒤 모델의 설정을 튜닝하는 과정을 수행한 뒤 테스트 데이터를 통해 결과물을 산출한다.
- 하지만 이러한 과정도 검증 데이터에 **과대적합**될 가능성이 있다.(정보 누설의 개념에 핵심이 존재)
    - 과대적합 : 학습데이터에서는 좋은 성능을 내나, 실제 데이터에서는 성능이 떨어지는 현상
    - 정보누설 : 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델에 누설되는 현상
- 검증데이터에 과대적합이 일어난다면 이후 테스트 세트를 이용한다.(모델은 테스트 세트에 대한 어떤 정보도 알지 못해야 한다.)
- 대표적 기법
    - 단순 홀드아웃 검증 : 데이터의 일정량을 테스트 세트로 떼어놓고 나머지 데이터에서 훈련을 진행하고 테스트 세트로 평가한다.(검증을 위해서 검증용을 따로 분리)
    - K-겹 교차검증 : 데이터를 동일한 크기를 가지는 K개의 분할로 나눈다. 각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 I로 평가한다. 이를 통해 얻어진 최종 점수는 이를 평균한다.
![image](https://user-images.githubusercontent.com/37393115/154220411-4d100e4d-87dc-480f-a734-80e204d74fa4.png)
    - 셔플링을 사용한 반복 K-겹 교차 검증 : 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용한다. K겹 교차 검증을 여러번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞는다. 최종점수는 모든 k겹 교차 검증을 실행해서 얻은 점수의 평균이 된다.

## 2. 평가방식을 선택할 때 유의할 점
1. 대표성이 있어야 한다.
2. 과거에서 미래까지의 시간의 연속이 존재하는 데이터는 무작위로 섞지 말아야 한다.
3. 데이터의 중복을 방지해야 한다.

# 3. 전처리, 특성 공학 및 특성학습

## 1. 데이터 전처리
- 벡터화 : 신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서이다. 어떤 형식의 데이터라도 처리를 위해서 텐서로 변환하는 과정이 필요한데 이를 **벡터화**라고 한다.
- 정규화 : 데이터를 네트워크에 주입하기 전에 각 특성간의 간격을 맞춰주는 과정(0과 1사이의 표준정규분포에 가깝도록 만드는 것이다.)
![image](https://user-images.githubusercontent.com/37393115/154220517-0b22ef31-76ec-4183-b05f-7327f5e92507.png)

- 결측치 다루기 : 누락된 값이 존재하면 신경망이 이를 인식하지 못할 가능성 존재 즉, 오류로이어지기 때문에 이를 다뤄줄 필요가 있음(채워주거나 임의의 값을 부여)

## 2. 특성공학
- 특성 공학은 데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계
- 모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 함
- 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만들어 준다.
- 최근 딥러닝은 대부분 특성 공학이 필요하지 않음 -> 신경망이 자동으로 원본 데이터에서 유용한 특성을 추출할 수 있기 때문이다.